# Copyright (c) Ultraviolet
# SPDX-License-Identifier: Apache-2.0

# Architecture
BR2_x86_64=y

# System
BR2_TARGET_GENERIC_HOSTNAME="cube"
BR2_TARGET_GENERIC_ISSUE="Welcome to Cube AI"
BR2_PACKAGE_DHCP=y
BR2_PACKAGE_DHCP_CLIENT=y
BR2_INIT_SYSTEMD=y
BR2_SYSTEM_BIN_SH_BASH=y

# Filesystem
# BR2_TARGET_ROOTFS_TAR is not set
BR2_TARGET_ROOTFS_CPIO=y
BR2_TARGET_ROOTFS_CPIO_FULL=y
BR2_TARGET_ROOTFS_CPIO_GZIP=y

# Image
BR2_ROOTFS_POST_BUILD_SCRIPT="$(BR2_EXTERNAL_CUBE_PATH)/board/cube/post-build.sh"

# Image
BR2_ROOTFS_POST_IMAGE_SCRIPT="$(BR2_EXTERNAL_CUBE_PATH)/board/cube/post-image.sh"
BR2_ROOTFS_POST_SCRIPT_ARGS="$(BR2_DEFCONFIG)"

# Linux headers same as kernel
BR2_PACKAGE_HOST_LINUX_HEADERS_CUSTOM_6_11=y
BR2_TOOLCHAIN_HEADERS_AT_LEAST_6_10=y
BR2_TOOLCHAIN_HEADERS_AT_LEAST_6_11=y
BR2_TOOLCHAIN_HEADERS_LATEST=y
BR2_TOOLCHAIN_HEADERS_AT_LEAST="6.11"

# Kernel
BR2_LINUX_KERNEL=y
BR2_LINUX_KERNEL_CUSTOM_GIT=y
BR2_LINUX_KERNEL_CUSTOM_REPO_URL="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git"
BR2_LINUX_KERNEL_CUSTOM_REPO_VERSION="v6.11"
BR2_LINUX_KERNEL_VERSION="v6.11"
BR2_LINUX_KERNEL_PATCH=""
BR2_LINUX_KERNEL_USE_CUSTOM_CONFIG=y
BR2_LINUX_KERNEL_CUSTOM_CONFIG_FILE="$(BR2_EXTERNAL_CUBE_PATH)/board/cube/linux.config"
BR2_LINUX_KERNEL_NEEDS_HOST_LIBELF=y
BR2_LINUX_KERNEL_NEEDS_HOST_OPENSSL=y

# host-qemu for gitlab testing
BR2_PACKAGE_HOST_QEMU=y
BR2_PACKAGE_HOST_QEMU_SYSTEM_MODE=y

# Docker
BR2_PACKAGE_LIBSECCOMP_ARCH_SUPPORTS=y
BR2_PACKAGE_LIBSECCOMP=y
BR2_PACKAGE_CA_CERTIFICATES=y
BR2_PACKAGE_DOCKER_CLI=y
BR2_PACKAGE_DOCKER_COMPOSE=y
BR2_PACKAGE_DOCKER_ENGINE=y
BR2_PACKAGE_CONTAINERD=y
BR2_PACKAGE_RUNC=y
BR2_PACKAGE_IPTABLES=y

BR2_PACKAGE_GIT=y

BR2_PACKAGE_LIBCURL=y
BR2_PACKAGE_OPENSSL=y
BR2_PACKAGE_LIBOPENSSL=y
BR2_PACKAGE_LIBOPENSSL_BIN=y
BR2_PACKAGE_LIBRESSL_ARCH_SUPPORTS=y
BR2_PACKAGE_HAS_OPENSSL=y
BR2_PACKAGE_PROVIDES_OPENSSL="libopenssl"
BR2_PACKAGE_PROVIDES_HOST_OPENSSL="host-libopenssl"

BR2_PACKAGE_QUOTA=y
BR2_PACKAGE_QUOTATOOL=y

BR2_TARGET_GENERIC_PASSWD_SHA512=y
BR2_TARGET_GENERIC_PASSWD_METHOD="sha-512"

BR2_TARGET_ENABLE_ROOT_LOGIN=y
BR2_TARGET_GENERIC_ROOT_PASSWD="m2N2Lfno"

BR2_PACKAGE_HOST_MKPASSWD=y

BR2_PACKAGE_HTOP=y

# SSH
BR2_PACKAGE_OPENSSH=y
BR2_PACKAGE_OPENSSH_CLIENT=y
BR2_PACKAGE_OPENSSH_SERVER=y
BR2_PACKAGE_OPENSSH_KEY_UTILS=y
BR2_PACKAGE_OPENSSH_SANDBOX=y

# ==============================================================================
# Cube AI Services
# ==============================================================================

# Go toolchain (required for cube-agent and ollama)
BR2_PACKAGE_HOST_GO_TARGET_ARCH_SUPPORTS=y
BR2_PACKAGE_HOST_GO_TARGET_CGO_LINKING_SUPPORTS=y

# Cube Agent
BR2_PACKAGE_CUBE_AGENT=y
BR2_PACKAGE_CUBE_AGENT_INSTANCE_ID="cube-agent-01"
BR2_PACKAGE_CUBE_AGENT_HOST="0.0.0.0"
BR2_PACKAGE_CUBE_AGENT_PORT="7001"
BR2_PACKAGE_CUBE_AGENT_LOG_LEVEL="info"

# LLM Backend Selection (choose one)
# Default: Ollama
BR2_PACKAGE_CUBE_AGENT_BACKEND_OLLAMA=y
# BR2_PACKAGE_CUBE_AGENT_BACKEND_VLLM is not set
# BR2_PACKAGE_CUBE_AGENT_BACKEND_CUSTOM is not set
# BR2_PACKAGE_CUBE_AGENT_TARGET_URL="" (only used with BACKEND_CUSTOM)

# Ollama (enabled via cube-agent backend selection)
BR2_PACKAGE_OLLAMA=y
BR2_PACKAGE_OLLAMA_MODELS=y
# BR2_PACKAGE_OLLAMA_CUSTOM_MODELS="llama2:7b mistral:7b"
# BR2_PACKAGE_OLLAMA_GPU_SUPPORT is not set
# BR2_PACKAGE_OLLAMA_GPU_NVIDIA is not set
# BR2_PACKAGE_OLLAMA_GPU_AMD is not set

# vLLM Alternative (uncomment to use instead of Ollama)
# Note: Only enable ONE LLM backend at a time
# Also requires Python3 and PyTorch to be configured
# BR2_PACKAGE_VLLM is not set
# BR2_PACKAGE_VLLM_MODEL="microsoft/DialoGPT-medium"
# BR2_PACKAGE_VLLM_GPU_MEMORY="0.85"
# BR2_PACKAGE_VLLM_MAX_MODEL_LEN="1024"
# BR2_PACKAGE_VLLM_CUSTOM_MODEL_PATH=""

# Python3 (required for vLLM - uncomment if using vLLM)
# BR2_PACKAGE_PYTHON3=y
# BR2_PACKAGE_PYTHON_NUMPY=y
# BR2_PACKAGE_PYTHON_PYTORCH=y (needs to be available/configured)
# BR2_PACKAGE_PYTHON_TRANSFORMERS=y

# Additional utilities for debugging
BR2_PACKAGE_CURL=y
BR2_PACKAGE_JQ=y
BR2_PACKAGE_PROCPS_NG=y

# ==============================================================================
# Configuration Notes:
# ==============================================================================
# 1. Cube Agent will start automatically and connect to the selected backend
# 2. Default backend: Ollama (http://localhost:11434)
# 3. Alternative backend: vLLM (http://localhost:8000)
# 4. To switch backends:
#    - Disable current backend option
#    - Enable desired backend option
#    - Rebuild with 'make clean && make'
# 5. Model installation:
#    - Ollama: Models pulled on first boot (see BR2_PACKAGE_OLLAMA_MODELS)
#    - vLLM: Downloaded from HuggingFace or use custom path
# 6. GPU support requires additional driver configuration
# ==============================================================================
