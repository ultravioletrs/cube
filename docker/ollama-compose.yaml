# Copyright (c) Ultraviolet
# SPDX-License-Identifier: Apache-2.0

volumes:
  open-webui:
    driver: local
  ollama:
    driver: local

services:
  ollama:
    profiles: ["ollama", "default"]
    container_name: ollama
    image: ollama/ollama:latest # For AMD GPU, use ollama/ollama:0.3.8-rocm
    restart: unless-stopped
    volumes:
      - ollama:/root/.ollama
    tty: true
    networks:
      - cube-network
    # # Uncomment the following lines to enable AMD GPU support
    # devices:
    #   - /dev/dri:/dev/dri
    #   - /dev/kfd:/dev/kfd
    # environment:
    #   - "HSA_OVERRIDE_GFX_VERSION=${HSA_OVERRIDE_GFX_VERSION-11.0.0}"

    # # Uncomment the following lines to enable Nvidia GPU support
    # runtime: nvidia
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES-all}
    #   - NVIDIA_DRIVER_CAPABILITIES=${NVIDIA_DRIVER_CAPABILITIES-compute,utility}

  pull-tinyllama:
    profiles: ["ollama", "default"]
    image: docker:27.3.1
    container_name: pull-tinyllama
    restart: on-failure
    depends_on:
      - ollama
    entrypoint: /bin/sh
    command: -c "docker exec ollama ollama run tinyllama:1.1b"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - cube-network

  pull-gemma:
    profiles: ["ollama", "default"]
    image: docker:27.3.1
    container_name: pull-gemma
    restart: on-failure
    depends_on:
      - ollama
    entrypoint: /bin/sh
    command: -c "docker exec ollama ollama run gemma:2b"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - cube-network

  pull-gpt-oss:
    profiles: ["ollama", "default"]
    image: docker:27.3.1
    container_name: pull-gpt-oss
    restart: on-failure
    depends_on:
      - ollama
    entrypoint: /bin/sh
    command: -c "docker exec ollama ollama run gpt-oss:latest"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - cube-network

  pull-llama:
    profiles: ["ollama", "default"]
    image: docker:27.3.1
    container_name: pull-llama
    restart: on-failure
    depends_on:
      - ollama
    entrypoint: /bin/sh
    command: -c "docker exec ollama ollama run llama3.2:latest"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - cube-network

  pull-starcoder2:
    profiles: ["ollama", "default"]
    image: docker:27.3.1
    container_name: pull-starcoder2
    restart: on-failure
    depends_on:
      - ollama
    entrypoint: /bin/sh
    command: -c "docker exec ollama ollama pull starcoder2:3b"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - cube-network

  pull-nomic-embed-text:
    profiles: ["ollama", "default"]
    image: docker:27.3.1
    container_name: pull-nomic-embed-text
    restart: on-failure
    depends_on:
      - ollama
    entrypoint: /bin/sh
    command: -c "docker exec ollama ollama pull nomic-embed-text:v1.5"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - cube-network
