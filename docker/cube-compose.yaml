# Copyright (c) Ultraviolet
# SPDX-License-Identifier: Apache-2.0

volumes:
  opensearch-data:
  cube-proxy-db-volume:
  cube-guardrails-db-volume:

services:
  opensearch:
    image: opensearchproject/opensearch:2.11.0
    container_name: opensearch
    environment:
      - discovery.type=single-node
      - plugins.security.disabled=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
      - "9600:9600"
    volumes:
      - opensearch-data:/usr/share/opensearch/data
    networks:
      - cube-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  opensearch-init:
    image: curlimages/curl:latest
    container_name: opensearch-init
    depends_on:
      opensearch:
        condition: service_healthy
    networks:
      - cube-network
    volumes:
      - ./opensearch-index-template.json:/tmp/index-template.json:ro
    command: >
      sh -c '
        echo "Creating index template for audit logs...";
        curl -X PUT "http://opensearch:9200/_index_template/cube-audit-template" -H "Content-Type: application/json" -d @/tmp/index-template.json;
        
        echo "";
        echo "OpenSearch setup complete!";
        curl -s "http://opensearch:9200/_cat/indices?v";
      '
    restart: "no"

  fluent-bit:
    image: fluent/fluent-bit:2.2
    container_name: fluent-bit
    # Run as root because the Docker container log directory (including the
    # snap-docker data root at /var/snap/docker/common/var-lib-docker) is owned
    # by root with restricted permissions. Fluent Bit must be able to read
    # container log files directly from the host filesystem, which requires
    # root-level access when docker is installed via snap.
    user: "0:0"
    volumes:
      - ./fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - ./parsers.conf:/fluent-bit/etc/parsers.conf:ro
      - ${DOCKER_ROOT_DIR:-/var/lib/docker}/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      opensearch:
        condition: service_healthy
      opensearch-init:
        condition: service_completed_successfully
    networks:
      - cube-network
    restart: unless-stopped
  
  cube-guardrails-db:
    image: postgres:16.2-alpine
    container_name: cube-guardrails-db
    restart: on-failure
    environment:
      POSTGRES_USER: ${UV_GUARDRAILS_DB_USER}
      POSTGRES_PASSWORD: ${UV_GUARDRAILS_DB_PASS}
      POSTGRES_DB: ${UV_GUARDRAILS_DB_NAME}
    networks:
      - cube-network
    volumes:
      - cube-guardrails-db-volume:/var/lib/postgresql/data

  cube-guardrails:
    container_name: guardrails
    image: ghcr.io/ultravioletrs/cube/guardrails:latest
    networks:
      - cube-network
    restart: unless-stopped
    depends_on:
      - cube-guardrails-db
    environment:
      - PYTHONPATH=/app
      - UVICORN_HOST=0.0.0.0
      - UVICORN_PORT=8001
      - UVICORN_LOG_LEVEL=info
      - TRANSFORMERS_CACHE=/app/cache
      - HF_HOME=/app/cache
      - XDG_CACHE_HOME=/app/cache
      - UV_GUARDRAILS_DB_HOST=${UV_GUARDRAILS_DB_HOST}
      - UV_GUARDRAILS_DB_PORT=${UV_GUARDRAILS_DB_PORT}
      - UV_GUARDRAILS_DB_USER=${UV_GUARDRAILS_DB_USER}
      - UV_GUARDRAILS_DB_PASS=${UV_GUARDRAILS_DB_PASS}
      - UV_GUARDRAILS_DB_NAME=${UV_GUARDRAILS_DB_NAME}
    volumes:
      - ../guardrails/rails:/app/rails:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/guardrails/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    labels:
      - "logging=guardrails"
      - "service=guardrails"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "logging,service"
        tag: "guardrails|{{.Name}}"


  cube-agent:
    container_name: cube-agent
    image: ghcr.io/ultravioletrs/cube/agent:latest
    profiles: ["default", "ollama", "vllm"]
    restart: on-failure
    networks:
      - cube-network
    environment:
      UV_CUBE_AGENT_LOG_LEVEL: ${UV_CUBE_AGENT_LOG_LEVEL}
      UV_CUBE_AGENT_HOST: ${UV_CUBE_AGENT_HOST}
      UV_CUBE_AGENT_PORT: ${UV_CUBE_AGENT_PORT}
      UV_CUBE_AGENT_SERVER_CERT: ${UV_CUBE_AGENT_SERVER_CERT}
      UV_CUBE_AGENT_SERVER_KEY: ${UV_CUBE_AGENT_SERVER_KEY}
      UV_CUBE_AGENT_INSTANCE_ID: ${UV_CUBE_AGENT_INSTANCE_ID}
      UV_CUBE_AGENT_TARGET_URL: ${UV_CUBE_AGENT_TARGET_URL}
      SMQ_SEND_TELEMETRY: ${SMQ_SEND_TELEMETRY}
      SMQ_JAEGER_URL: ${SMQ_JAEGER_URL}
      SMQ_JAEGER_TRACE_RATIO: ${SMQ_JAEGER_TRACE_RATIO}
    labels:
      # Labels for log parsing
      logging: "cube-agent"
      service: "agent"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "logging,service"
        tag: "cube-agent|{{.Name}}"
    depends_on:
      - fluent-bit
    ports:
      - ${UV_CUBE_AGENT_PORT}:${UV_CUBE_AGENT_PORT}

  cube-proxy-db:
    image: postgres:16.1-alpine
    container_name: cube-proxy-db
    restart: on-failure
    environment:
      POSTGRES_USER: ${UV_CUBE_PROXY_DB_USER}
      POSTGRES_PASSWORD: ${UV_CUBE_PROXY_DB_PASS}
      POSTGRES_DB: ${UV_CUBE_PROXY_DB_NAME}
    networks:
      - cube-network
    volumes:
      - cube-proxy-db-volume:/var/lib/postgresql/data

  cube-proxy:
    container_name: cube-proxy
    image: ghcr.io/ultravioletrs/cube/proxy:latest
    restart: on-failure
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "logging,service"
        tag: "cube-proxy|{{.Name}}"
    networks:
      - cube-network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - auth
      - cube-proxy-db
      - fluent-bit
    environment:
      UV_CUBE_PROXY_LOG_LEVEL: ${UV_CUBE_PROXY_LOG_LEVEL}
      UV_CUBE_AGENT_URL: ${UV_CUBE_AGENT_URL}
      UV_CUBE_PROXY_HOST: ${UV_CUBE_PROXY_HOST}
      UV_CUBE_PROXY_PORT: ${UV_CUBE_PROXY_PORT}
      UV_CUBE_PROXY_SERVER_CERT: ${UV_CUBE_PROXY_SERVER_CERT}
      UV_CUBE_PROXY_SERVER_KEY: ${UV_CUBE_PROXY_SERVER_KEY}
      SMQ_SEND_TELEMETRY: ${SMQ_SEND_TELEMETRY}
      UV_CUBE_PROXY_INSTANCE_ID: ${UV_CUBE_PROXY_INSTANCE_ID}
      UV_CUBE_PROXY_ROUTER_CONFIG: ${UV_CUBE_PROXY_ROUTER_CONFIG}
      SMQ_JAEGER_URL: ${SMQ_JAEGER_URL}
      SMQ_JAEGER_TRACE_RATIO: ${SMQ_JAEGER_TRACE_RATIO}
      SMQ_AUTH_GRPC_URL: ${SMQ_AUTH_GRPC_URL}
      SMQ_AUTH_GRPC_TIMEOUT: ${SMQ_AUTH_GRPC_TIMEOUT}
      SMQ_AUTH_GRPC_CLIENT_CERT: ${SMQ_AUTH_GRPC_CLIENT_CERT:+/auth-grpc-client.crt}
      SMQ_AUTH_GRPC_CLIENT_KEY: ${SMQ_AUTH_GRPC_CLIENT_KEY:+/auth-grpc-client.key}
      SMQ_AUTH_GRPC_SERVER_CA_CERTS: ${SMQ_AUTH_GRPC_SERVER_CA_CERTS:+/auth-grpc-server-ca.crt}
      UV_CUBE_PROXY_DB_HOST: ${UV_CUBE_PROXY_DB_HOST}
      UV_CUBE_PROXY_DB_PORT: ${UV_CUBE_PROXY_DB_PORT}
      UV_CUBE_PROXY_DB_USER: ${UV_CUBE_PROXY_DB_USER}
      UV_CUBE_PROXY_DB_PASS: ${UV_CUBE_PROXY_DB_PASS}
      UV_CUBE_PROXY_DB_NAME: ${UV_CUBE_PROXY_DB_NAME}
      UV_CUBE_PROXY_DB_SSL_MODE: ${UV_CUBE_PROXY_DB_SSL_MODE}
      UV_CUBE_PROXY_DB_SSL_CERT: ${UV_CUBE_PROXY_DB_SSL_CERT}
      UV_CUBE_PROXY_DB_SSL_KEY: ${UV_CUBE_PROXY_DB_SSL_KEY}
      UV_CUBE_PROXY_DB_SSL_ROOT_CERT: ${UV_CUBE_PROXY_DB_SSL_ROOT_CERT}
      # Agent mTLS Configuration (optional - only set when certs are provided)
      UV_CUBE_AGENT_CLIENT_CERT: ${UV_CUBE_AGENT_CLIENT_CERT:+/etc/cube/agent-certs/client.crt}
      UV_CUBE_AGENT_CLIENT_KEY: ${UV_CUBE_AGENT_CLIENT_KEY:+/etc/cube/agent-certs/client.key}
      UV_CUBE_AGENT_SERVER_CA_CERTS: ${UV_CUBE_AGENT_SERVER_CA_CERTS:+/etc/cube/agent-certs/ca.crt}
    volumes:
      - type: bind
        source: ./config.json
        target: /etc/cube/proxy/config.json
        read_only: true
      # Auth gRPC client certificates
      - type: bind
        source: ${SMQ_AUTH_GRPC_CLIENT_CERT:-ssl/certs/dummy/client_cert}
        target: /auth-grpc-client${SMQ_AUTH_GRPC_CLIENT_CERT:+.crt}
        bind:
          create_host_path: true
      - type: bind
        source: ${SMQ_AUTH_GRPC_CLIENT_KEY:-ssl/certs/dummy/client_key}
        target: /auth-grpc-client${SMQ_AUTH_GRPC_CLIENT_KEY:+.key}
        bind:
          create_host_path: true
      - type: bind
        source: ${SMQ_AUTH_GRPC_SERVER_CA_CERTS:-ssl/certs/dummy/server_ca}
        target: /auth-grpc-server-ca${SMQ_AUTH_GRPC_SERVER_CA_CERTS:+.crt}
        bind:
          create_host_path: true
      # Agent mTLS client certificates (optional)
      - type: bind
        source: ${UV_CUBE_AGENT_CLIENT_CERT:-ssl/certs/dummy/client_cert}
        target: /etc/cube/agent-certs/client${UV_CUBE_AGENT_CLIENT_CERT:+.crt}
        bind:
          create_host_path: true
      - type: bind
        source: ${UV_CUBE_AGENT_CLIENT_KEY:-ssl/certs/dummy/client_key}
        target: /etc/cube/agent-certs/client${UV_CUBE_AGENT_CLIENT_KEY:+.key}
        bind:
          create_host_path: true
      - type: bind
        source: ${UV_CUBE_AGENT_SERVER_CA_CERTS:-ssl/certs/dummy/server_ca}
        target: /etc/cube/agent-certs/ca${UV_CUBE_AGENT_SERVER_CA_CERTS:+.crt}
        bind:
          create_host_path: true
      # Attestation policy
      - type: bind
        source: ${UV_CUBE_AGENT_ATTESTATION_POLICY:-./attestation-policy.json}
        target: /etc/cube/attestation-policy.json
        read_only: true
    ports:
      - ${UV_CUBE_PROXY_PORT}:${UV_CUBE_PROXY_PORT}
    labels:
      logging: "cube-proxy"
      service: "proxy"
